{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e43b5d36-b656-4077-96e8-84590f6b140d",
      "metadata": {
        "id": "e43b5d36-b656-4077-96e8-84590f6b140d"
      },
      "source": [
        "# Milky Way Mapper's Galaxy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d8ff0b",
      "metadata": {
        "id": "51d8ff0b"
      },
      "source": [
        "## Section 7: Paper Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96d457f8-beb0-4f9c-9886-de9ecdcf08ac",
      "metadata": {
        "id": "96d457f8-beb0-4f9c-9886-de9ecdcf08ac"
      },
      "outputs": [],
      "source": [
        "#Import some things\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "import astropy.coordinates as coord\n",
        "import astropy.units as u\n",
        "from astropy.io import fits, ascii\n",
        "from astropy.table import Table\n",
        "from astropy.coordinates import SkyCoord\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7525f7b4-27eb-4abd-87c3-916ab17aef30",
      "metadata": {
        "id": "7525f7b4-27eb-4abd-87c3-916ab17aef30"
      },
      "outputs": [],
      "source": [
        "#load in the data (may have to change this for wherever you downloaded your file)\n",
        "#in google colab you can get the file using\n",
        "#!wget https://dr19.sdss.org/sas/dr19/spectro/astra/0.6.0/summary/astraAllStarASPCAP-0.6.0.fits.gz \n",
        "\n",
        "filename='astraAllStarASPCAP-0.6.0.fits'\n",
        "tb = fits.open(filename)\n",
        "header=tb[2].header\n",
        "data = tb[2].data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8f63592d-5b8d-4c71-b64b-9001481db68e",
      "metadata": {
        "id": "8f63592d-5b8d-4c71-b64b-9001481db68e"
      },
      "outputs": [],
      "source": [
        "good=np.where((data['teff'] > 3700) & (data['teff'] < 5300) &\n",
        "               (data['logg'] > 0.9) & (data['logg'] < 3.3) &\n",
        "               (data['m_h_atm'] > -2.0) & (data['m_h_atm'] < 0.6) &\n",
        "               (data['flag_bad']==False) )\n",
        "\n",
        "data_masked=data[good]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f69c238-4e3a-49a3-a0e1-c945d4e3cb26",
      "metadata": {
        "id": "3f69c238-4e3a-49a3-a0e1-c945d4e3cb26"
      },
      "source": [
        "## Training Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e198e51e-627e-43a1-aca4-4b421a89b783",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "e198e51e-627e-43a1-aca4-4b421a89b783",
        "outputId": "460230e0-b74d-4eb6-8aaf-e57af4173548"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><i>Table length=124340</i>\n",
              "<table id=\"table1791970676224\" class=\"table-striped table-bordered table-condensed\">\n",
              "<thead><tr><th>TIC</th><th>Star_type</th><th>Age</th><th>νmax</th><th>Radius_gaia</th><th>Teff_xgboost</th><th>M_H_xgboost</th><th>Logg_xgboost</th><th>Logg_seis</th><th>E_Logg_seis</th><th>Mass_seis</th><th>E_Mass_seis</th><th>Initial_mass</th><th>Teff_rgb</th><th>Teff_rc</th><th>Median_age_rgb</th><th>Median_age_rc</th><th>E_lower_age_rgb</th><th>E_upper_age_rgb</th><th>E_lower_age_rc</th><th>E_upper_age_rc</th><th>Teff_diff</th><th>Flag</th></tr></thead>\n",
              "<thead><tr><th>int64</th><th>str5</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th></tr></thead>\n",
              "<tr><td>347020604</td><td>Clump</td><td>4.933697638292032</td><td>32.2</td><td>10.8</td><td>4766.6</td><td>-0.161</td><td>2.432</td><td>2.4173752480453827</td><td>0.0366707608673319</td><td>1.1120077414967078</td><td>0.0588614326241161</td><td>1.2303580537284051</td><td>4573.560449427352</td><td>4592.554431111989</td><td>7.362373244</td><td>4.928036510093708</td><td>6.081092717</td><td>8.892029592</td><td>4.299934128259921</td><td>6.1356166056543815</td><td>174.04556888801108</td><td>0</td></tr>\n",
              "<tr><td>365250045</td><td>RGB</td><td>5.919390103924665</td><td>33.0</td><td>10.8</td><td>4931.7</td><td>-0.342</td><td>2.455</td><td>2.4229857865111493</td><td>0.0357953759646522</td><td>1.126466677413624</td><td>0.056320640605</td><td>1.1264672739859862</td><td>4667.980210870163</td><td>4834.105313542321</td><td>5.948811656</td><td>4.27541564590489</td><td>5.120775603</td><td>7.010332121</td><td>3.7125897559954217</td><td>4.990341868284544</td><td>97.59468645767902</td><td>0</td></tr>\n",
              "<tr><td>377058143</td><td>RGB</td><td>10.659761236332615</td><td>59.1</td><td>7.3</td><td>4732.1</td><td>-0.519</td><td>2.615</td><td>2.677206425366256</td><td>0.0648094481080465</td><td>0.9241388003056158</td><td>0.0471439463924816</td><td>0.9241384053448526</td><td>4809.243666602538</td><td>4845.904744096898</td><td>11.11556225</td><td>5.653288060595535</td><td>9.53022434</td><td>12.72313934</td><td>4.950738403099905</td><td>6.798479977799735</td><td>-113.8047440968976</td><td>0</td></tr>\n",
              "<tr><td>347548024</td><td>RGB</td><td>4.2433496208314345</td><td>33.2</td><td>11.5</td><td>4634.4</td><td>-0.213</td><td>2.388</td><td>2.4218043131513705</td><td>0.0720751969086103</td><td>1.2737524436569616</td><td>0.0852469599851652</td><td>1.2737527853903323</td><td>4625.72134164397</td><td>4775.614677688445</td><td>4.196919598</td><td>3.1842561951173276</td><td>3.279495422</td><td>5.737266629</td><td>2.7003724708906987</td><td>3.926199760609352</td><td>-141.2146776884456</td><td>0</td></tr>\n",
              "<tr><td>328321210</td><td>Clump</td><td>5.297976079237009</td><td>35.7</td><td>9.6</td><td>4982.0</td><td>-0.526</td><td>2.441</td><td>2.4671643779400427</td><td>0.0755464565388593</td><td>0.9853531626679212</td><td>0.0677079590734425</td><td>1.121116190405825</td><td>4737.2709053692715</td><td>4762.055765851048</td><td>9.131354832</td><td>5.481214180765681</td><td>6.619391066</td><td>11.17929356</td><td>4.57496878200937</td><td>6.826530999798273</td><td>219.9442341489521</td><td>0</td></tr>\n",
              "<tr><td>328321103</td><td>RGB</td><td>3.76901613056093</td><td>34.5</td><td>11.4</td><td>4765.0</td><td>-0.277</td><td>2.533</td><td>2.438719284222579</td><td>0.0355087401732596</td><td>1.3014095644450476</td><td>0.0659512559797257</td><td>1.301409615256684</td><td>4669.883118807332</td><td>4814.012809659391</td><td>3.7183394</td><td>2.964010779639734</td><td>3.222621332</td><td>4.398228001</td><td>2.51085645776994</td><td>3.520642797490074</td><td>-49.01280965939077</td><td>0</td></tr>\n",
              "<tr><td>328324062</td><td>Clump</td><td>2.303632505100647</td><td>41.3</td><td>11.3</td><td>4792.0</td><td>0.085</td><td>2.617</td><td>2.5205598637381987</td><td>0.0266418863144747</td><td>1.5438382675435354</td><td>0.0669944467135548</td><td>1.6114631436790468</td><td>4552.67752843955</td><td>4567.434071459611</td><td>2.700422808</td><td>2.2357112051063632</td><td>2.255954628</td><td>3.155200636</td><td>1.9961451072036724</td><td>2.638300639580447</td><td>224.565928540389</td><td>0</td></tr>\n",
              "<tr><td>328400618</td><td>Clump</td><td>2.159728298323744</td><td>44.1</td><td>10.5</td><td>4910.2</td><td>-0.319</td><td>2.472</td><td>2.557435937807216</td><td>0.0739867137774788</td><td>1.4511074516675977</td><td>0.0926043469167527</td><td>1.5165343396975142</td><td>4767.690838544538</td><td>4778.114861413547</td><td>2.561181642</td><td>2.157582282377099</td><td>2.082416797</td><td>3.109146383</td><td>1.7850147949917456</td><td>2.6517500725099072</td><td>132.08513858645256</td><td>0</td></tr>\n",
              "<tr><td>328255103</td><td>Clump</td><td>6.418514994888695</td><td>31.9</td><td>10.8</td><td>4686.6</td><td>0.019</td><td>2.433</td><td>2.406553604071016</td><td>0.0559847430029249</td><td>1.0846413740056715</td><td>0.0674371343640133</td><td>1.18744043140101</td><td>4471.252872082005</td><td>4487.596554271885</td><td>9.075683921</td><td>6.586728636664553</td><td>7.526636104</td><td>11.69375071</td><td>5.35273124007062</td><td>7.587960124712628</td><td>199.00344572811537</td><td>0</td></tr>\n",
              "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
              "<tr><td>24293754</td><td>Clump</td><td>7.270499767640112</td><td>30.9</td><td>10.2</td><td>4680.1</td><td>-0.2</td><td>2.428</td><td>2.399207980219463</td><td>0.0298296961867419</td><td>0.9512470957539596</td><td>0.0441236882134543</td><td>1.0956080340537082</td><td>4548.956849105674</td><td>4579.390412244217</td><td>12.42068752</td><td>7.310600524515545</td><td>10.69207048</td><td>15.40925913</td><td>6.310366637090926</td><td>8.712502028260396</td><td>100.7095877557831</td><td>0</td></tr>\n",
              "<tr><td>444151014</td><td>RGB</td><td>1.3293989221533338</td><td>42.0</td><td>12.7</td><td>4564.5</td><td>0.235</td><td>2.428</td><td>2.5241027057740677</td><td>0.0302942508281642</td><td>1.9660527727614991</td><td>0.1066372801170731</td><td>1.9660528317165893</td><td>4551.681217126331</td><td>4558.626214039348</td><td>1.337344976</td><td>1.2193055256945164</td><td>1.107826687</td><td>1.66771992</td><td>1.0892608398607586</td><td>1.455594566352458</td><td>5.87378596065173</td><td>0</td></tr>\n",
              "<tr><td>439387397</td><td>RGB</td><td>10.886531443589943</td><td>38.6</td><td>9.3</td><td>4631.1</td><td>-0.248</td><td>2.499</td><td>2.489396578020239</td><td>0.0508134259270761</td><td>0.9733018061196635</td><td>0.0521761267719925</td><td>0.9733012519116058</td><td>4620.716367755734</td><td>4650.601883450058</td><td>10.99454201</td><td>6.314006485124088</td><td>9.032860348</td><td>13.20527487</td><td>5.211545198833982</td><td>7.635994733477046</td><td>-19.501883450057903</td><td>0</td></tr>\n",
              "<tr><td>439387373</td><td>RGB</td><td>13.559665913368113</td><td>52.9</td><td>7.7</td><td>4598.5</td><td>-0.206</td><td>2.636</td><td>2.6307613177683287</td><td>0.0258131672540484</td><td>0.9239059902913592</td><td>0.0373936421046703</td><td>0.923906214083602</td><td>4641.654812571993</td><td>4680.746214005319</td><td>13.70737483</td><td>7.753563029049198</td><td>12.2628135</td><td>15.12569441</td><td>6.896534907227312</td><td>8.865732312274117</td><td>-82.24621400531942</td><td>0</td></tr>\n",
              "<tr><td>415686794</td><td>Clump</td><td>3.5268592139224655</td><td>37.9</td><td>10.9</td><td>4773.3</td><td>0.112</td><td>2.631</td><td>2.483340981191912</td><td>0.0267072980726848</td><td>1.3184965052627895</td><td>0.0575078402125955</td><td>1.4340694281462223</td><td>4488.851912716716</td><td>4508.089132079645</td><td>4.837948927</td><td>3.4995127765543605</td><td>4.256064234</td><td>5.586369343</td><td>2.954016975950612</td><td>4.00273702323879</td><td>265.21086792035476</td><td>0</td></tr>\n",
              "<tr><td>99837810</td><td>Clump</td><td>11.042183147979149</td><td>28.1</td><td>10.4</td><td>4605.9</td><td>0.016</td><td>2.431</td><td>2.3499336495620113</td><td>0.0712269930351832</td><td>0.8828467704108918</td><td>0.0635229717437992</td><td>1.0255068506336564</td><td>4399.246020147388</td><td>4431.823017834595</td><td>19.82332468</td><td>10.657076041429718</td><td>15.87245997</td><td>24.47288804</td><td>8.222377635684587</td><td>13.862395309695891</td><td>174.07698216540484</td><td>0</td></tr>\n",
              "<tr><td>99821552</td><td>RGB</td><td>2.1627981000040437</td><td>25.0</td><td>15.1</td><td>4420.4</td><td>-0.067</td><td>2.14</td><td>2.282880926371518</td><td>0.0817620341485557</td><td>1.5948501340660617</td><td>0.1271293994256553</td><td>1.5948499544670982</td><td>4521.13258638862</td><td>4530.195881339838</td><td>2.059770856</td><td>1.8605694698050377</td><td>1.656739446</td><td>2.680530158</td><td>1.4738695107846194</td><td>2.5179584189392616</td><td>-109.79588133983816</td><td>0</td></tr>\n",
              "<tr><td>441029961</td><td>Clump</td><td>4.068854769155727</td><td>35.5</td><td>10.6</td><td>4782.2</td><td>-0.251</td><td>2.454</td><td>2.4586662614356354</td><td>0.0272611630299921</td><td>1.1780481987255331</td><td>0.0525955456468396</td><td>1.279547727713048</td><td>4647.035647055904</td><td>4663.605199793464</td><td>5.528992072</td><td>3.875785579258347</td><td>4.639599327</td><td>6.24384432</td><td>3.4206135944114515</td><td>4.660127921049435</td><td>118.59480020653608</td><td>0</td></tr>\n",
              "<tr><td>441015317</td><td>RGB</td><td>10.13177954</td><td>25.4</td><td>12.1</td><td>4410.4</td><td>0.043</td><td>2.251</td><td>2.298070483513228</td><td>0.0446639679644</td><td>1.0605381308578825</td><td>0.0621831423234216</td><td>1.0605384566787168</td><td>4412.812108453358</td><td>4428.713056662758</td><td>10.11310758</td><td>7.127798454945256</td><td>8.257605623</td><td>12.28754288</td><td>5.930333252764051</td><td>8.430542558191812</td><td>-18.31305666275875</td><td>0</td></tr>\n",
              "<tr><td>99818843</td><td>RGB</td><td>6.006672813122813</td><td>30.3</td><td>11.4</td><td>4484.3</td><td>-0.292</td><td>2.301</td><td>2.37918647277568</td><td>0.0789505179281383</td><td>1.134700334062554</td><td>0.0825100846064691</td><td>1.1347006565422713</td><td>4621.617923416667</td><td>4639.586052550128</td><td>6.183338205</td><td>4.118140285608963</td><td>4.912764406</td><td>7.972203552</td><td>3.446298354171621</td><td>5.439509135147377</td><td>-155.28605255012826</td><td>0</td></tr>\n",
              "</table></div>"
            ],
            "text/plain": [
              "<Table length=124340>\n",
              "   TIC    Star_type        Age         ...      Teff_diff       Flag\n",
              "  int64      str5        float64       ...       float64       int64\n",
              "--------- --------- ------------------ ... ------------------- -----\n",
              "347020604     Clump  4.933697638292032 ...  174.04556888801108     0\n",
              "365250045       RGB  5.919390103924665 ...   97.59468645767902     0\n",
              "377058143       RGB 10.659761236332615 ...  -113.8047440968976     0\n",
              "347548024       RGB 4.2433496208314345 ...  -141.2146776884456     0\n",
              "328321210     Clump  5.297976079237009 ...   219.9442341489521     0\n",
              "328321103       RGB   3.76901613056093 ...  -49.01280965939077     0\n",
              "328324062     Clump  2.303632505100647 ...    224.565928540389     0\n",
              "328400618     Clump  2.159728298323744 ...  132.08513858645256     0\n",
              "328255103     Clump  6.418514994888695 ...  199.00344572811537     0\n",
              "      ...       ...                ... ...                 ...   ...\n",
              " 24293754     Clump  7.270499767640112 ...   100.7095877557831     0\n",
              "444151014       RGB 1.3293989221533338 ...    5.87378596065173     0\n",
              "439387397       RGB 10.886531443589943 ... -19.501883450057903     0\n",
              "439387373       RGB 13.559665913368113 ...  -82.24621400531942     0\n",
              "415686794     Clump 3.5268592139224655 ...  265.21086792035476     0\n",
              " 99837810     Clump 11.042183147979149 ...  174.07698216540484     0\n",
              " 99821552       RGB 2.1627981000040437 ... -109.79588133983816     0\n",
              "441029961     Clump  4.068854769155727 ...  118.59480020653608     0\n",
              "441015317       RGB        10.13177954 ...  -18.31305666275875     0\n",
              " 99818843       RGB  6.006672813122813 ... -155.28605255012826     0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TESS\n",
        "tessraw = Table.read(\"Theodoridis2025.csv\", format=\"ascii\")\n",
        "#this one has an age column in Gyr already so we're just going to rename it Age\n",
        "tessraw['Final_age'].name='Age'\n",
        "hasagetess=np.where((tessraw['Age']==tessraw['Age']) & (tessraw['Age']>0.1) &(tessraw['Flag']==0))\n",
        "tess=tessraw[hasagetess]\n",
        "tess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c979c407-4098-406d-9ef0-b322b985bc80",
      "metadata": {
        "id": "c979c407-4098-406d-9ef0-b322b985bc80"
      },
      "outputs": [],
      "source": [
        "# # Age option 2 APOKASC-2 Pinsonneault et al. 2018\n",
        "# #Reading in the table, making sure all the tables have a column named Age in Gyr\n",
        "# # and that every star in the table has an Age\n",
        "# apokasc2raw = Table.read(\"Pinsonneault2018.txt\", format=\"ascii.cds\")\n",
        "# apokasc2raw['Age']=(10**np.array(apokasc2raw['LogAge'])/1000.) #Age was in log(Myr) so needs converting\n",
        "# hasagea2=np.where((apokasc2raw['Age']==apokasc2raw['Age']) & (apokasc2raw['Age']>0.1))\n",
        "# apokasc2=apokasc2raw[hasagea2]\n",
        "# apokasc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "842af861-cd4a-4cd8-8516-8a813f1531be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "842af861-cd4a-4cd8-8516-8a813f1531be",
        "outputId": "6055302e-8930-43ad-9c16-082e98643b24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><i>Table length=12291</i>\n",
              "<table id=\"table1791975019424\" class=\"table-striped table-bordered table-condensed\">\n",
              "<thead><tr><th>KIC</th><th>EvolState</th><th>ESSource</th><th>CatTab</th><th>SeisSource</th><th>SpecSource</th><th>NNumax</th><th>NDNu</th><th>Nquar</th><th>Numax</th><th>e_Numax</th><th>DNu</th><th>e_DNu</th><th>FDNu</th><th>e_FDNu</th><th>FNumax</th><th>Mass</th><th>e_Mass</th><th>Radius</th><th>e_Radius</th><th>logg-Seis</th><th>e_logg-Seis</th><th>Teff</th><th>e_Teff</th><th>logg-Spec</th><th>e_logg-Spec</th><th>[Fe/H]</th><th>e_[Fe/H]</th><th>[a/Fe]</th><th>e_[a/Fe]</th><th>[C/Fe]</th><th>e_[C/Fe]</th><th>[N/Fe]</th><th>e_[N/Fe]</th><th>InvRGaia</th><th>e_InvRGaia</th><th>AgeCat</th><th>AgeRGB</th><th>E_AgeRGB</th><th>e_AgeRGB</th><th>AgeRC</th><th>E_AgeRC</th><th>e_AgeRC</th><th>vsini</th><th>alphaCat</th><th>GaiaDR3</th><th>2MASS</th><th>Age</th></tr></thead>\n",
              "<thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>uHz</th><th>uHz</th><th>uHz</th><th>uHz</th><th></th><th></th><th></th><th>Msun</th><th>Msun</th><th>Rsun</th><th>Rsun</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>K</th><th>K</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th></th><th></th><th></th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>km / s</th><th></th><th></th><th></th><th></th></tr></thead>\n",
              "<thead><tr><th>int64</th><th>str7</th><th>str4</th><th>str8</th><th>str4</th><th>str4</th><th>int64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str7</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str5</th><th>int64</th><th>str23</th><th>float64</th></tr></thead>\n",
              "<tr><td>893214</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>15</td><td>40.5841</td><td>0.2874</td><td>4.3254</td><td>0.0289</td><td>1.0277</td><td>0.005</td><td>0.9976</td><td>1.4404</td><td>0.0602</td><td>11.0014</td><td>0.2055</td><td>2.5146</td><td>0.0042</td><td>4718.9233</td><td>44.7811</td><td>2.4559</td><td>0.058</td><td>-0.2617</td><td>0.058</td><td>0.0815</td><td>0.022</td><td>-0.0626</td><td>0.0135</td><td>0.2483</td><td>0.0164</td><td>0.082389</td><td>0.002866</td><td>RGB</td><td>2.8815</td><td>0.298</td><td>-0.2639</td><td>2.8815</td><td>0.298</td><td>-0.2639</td><td>0.0</td><td>Apoor</td><td>2050237616959273728</td><td>2MASS J19245967+3638183</td><td>2.8815</td></tr>\n",
              "<tr><td>1026180</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>35.6089</td><td>0.2338</td><td>3.9208</td><td>0.0265</td><td>0.9972</td><td>0.005</td><td>0.9936</td><td>1.5334</td><td>0.0633</td><td>12.2361</td><td>0.2278</td><td>2.4512</td><td>0.0039</td><td>4576.1016</td><td>40.5161</td><td>2.4066</td><td>0.058</td><td>0.2741</td><td>0.058</td><td>0.0215</td><td>0.022</td><td>0.0568</td><td>0.0084</td><td>0.3647</td><td>0.0107</td><td>0.085599</td><td>0.002161</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.1325</td><td>0.2754</td><td>-0.1905</td><td>0.0</td><td>Apoor</td><td>2050237174589477888</td><td>2MASS J19241923+3645378</td><td>3.1325</td></tr>\n",
              "<tr><td>1026309</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>8</td><td>4</td><td>18</td><td>16.6974</td><td>0.5675</td><td>1.9432</td><td>0.0805</td><td>1.0072</td><td>0.005</td><td>1.0205</td><td>2.642</td><td>0.518</td><td>23.2678</td><td>2.0993</td><td>2.1176</td><td>0.0148</td><td>4479.2246</td><td>39.7068</td><td>2.2388</td><td>0.058</td><td>0.1609</td><td>0.058</td><td>-0.0295</td><td>0.022</td><td>-0.0823</td><td>0.0088</td><td>0.2913</td><td>0.011</td><td>0.047943</td><td>0.001239</td><td>RGB_AGB</td><td>0.5842</td><td>0.1481</td><td>-0.109</td><td>0.7082</td><td>0.1832</td><td>-0.1405</td><td>0.0</td><td>Apoor</td><td>2050236934071312384</td><td>2MASS J19242636+3643594</td><td>0.5842</td></tr>\n",
              "<tr><td>1026452</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>18</td><td>34.3652</td><td>0.2256</td><td>3.9749</td><td>0.0268</td><td>0.9953</td><td>0.005</td><td>0.9936</td><td>1.4618</td><td>0.0599</td><td>11.9485</td><td>0.2215</td><td>2.451</td><td>0.0044</td><td>4910.6035</td><td>53.0693</td><td>2.4907</td><td>0.058</td><td>-0.2652</td><td>0.058</td><td>0.0658</td><td>0.022</td><td>0.0005</td><td>0.0189</td><td>0.1605</td><td>0.0222</td><td>0.075937</td><td>0.003795</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>2.6495</td><td>0.2319</td><td>-0.1919</td><td>0.0</td><td>Apoor</td><td>2050243050104808960</td><td>2MASS J19243452+3647244</td><td>2.6495</td></tr>\n",
              "<tr><td>1027110</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>8</td><td>4</td><td>18</td><td>6.5198</td><td>0.1616</td><td>1.1613</td><td>0.044</td><td>1.0511</td><td>0.005</td><td>1.0535</td><td>1.0367</td><td>0.1769</td><td>23.337</td><td>1.8791</td><td>1.6949</td><td>0.011</td><td>4194.4375</td><td>37.9582</td><td>1.7495</td><td>0.058</td><td>-0.3017</td><td>0.058</td><td>0.2615</td><td>0.022</td><td>0.1451</td><td>0.0109</td><td>0.1366</td><td>0.0131</td><td>0.040245</td><td>0.001509</td><td>RGB_AGB</td><td>9.0694</td><td>8.0551</td><td>-3.8133</td><td>7.2088</td><td>4.6171</td><td>-2.3475</td><td>0.0</td><td>Arich</td><td>2050239201814200192</td><td>2MASS J19250937+3644599</td><td>9.0694</td></tr>\n",
              "<tr><td>1027337</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>18</td><td>74.3689</td><td>0.4491</td><td>6.9661</td><td>0.0418</td><td>1.0282</td><td>0.005</td><td>0.9959</td><td>1.2676</td><td>0.0489</td><td>7.6702</td><td>0.133</td><td>2.7732</td><td>0.0038</td><td>4621.996</td><td>41.3674</td><td>2.7836</td><td>0.058</td><td>0.2081</td><td>0.058</td><td>0.0354</td><td>0.022</td><td>0.062</td><td>0.009</td><td>0.2898</td><td>0.0115</td><td>0.123008</td><td>0.0033</td><td>RGB</td><td>5.8519</td><td>0.5953</td><td>-0.5247</td><td>5.8519</td><td>0.5953</td><td>-0.5247</td><td>0.0</td><td>Apoor</td><td>2050240782362231552</td><td>2MASS J19252021+3647118</td><td>5.8519</td></tr>\n",
              "<tr><td>1027707</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>6</td><td>3</td><td>18</td><td>3.0206</td><td>0.0885</td><td>0.5593</td><td>0.0309</td><td>1.0265</td><td>0.005</td><td>1.0663</td><td>2.0033</td><td>0.4792</td><td>48.0566</td><td>5.5208</td><td>1.3484</td><td>0.0129</td><td>3961.365</td><td>35.9864</td><td>1.4062</td><td>0.058</td><td>0.1105</td><td>0.058</td><td>0.0356</td><td>0.022</td><td>0.0455</td><td>0.0079</td><td>0.1751</td><td>0.0094</td><td>0.018104</td><td>0.001509</td><td>RGB_AGB</td><td>1.3052</td><td>0.6198</td><td>-0.3779</td><td>1.5494</td><td>0.4593</td><td>-0.4138</td><td>0.0</td><td>Apoor</td><td>2050240129527252096</td><td>2MASS J19253846+3646103</td><td>1.3052</td></tr>\n",
              "<tr><td>1160655</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>5</td><td>2</td><td>18</td><td>1.5726</td><td>0.0502</td><td>0.3698</td><td>0.024</td><td>1.0608</td><td>0.005</td><td>1.0525</td><td>1.1903</td><td>0.3305</td><td>52.0838</td><td>6.9807</td><td>1.058</td><td>0.0139</td><td>3837.788</td><td>33.9314</td><td>0.9088</td><td>0.058</td><td>-0.1446</td><td>0.058</td><td>0.1098</td><td>0.022</td><td>0.0582</td><td>0.0089</td><td>0.2023</td><td>0.0105</td><td>0.018767</td><td>0.001236</td><td>RGB_AGB</td><td>5.7073</td><td>8.7454</td><td>-2.777</td><td>5.013</td><td>5.3362</td><td>-2.0267</td><td>0.0</td><td>Arich</td><td>2050252395953454464</td><td>2MASS J19232193+3650379</td><td>5.7073</td></tr>\n",
              "<tr><td>1160684</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>17</td><td>26.8674</td><td>0.1516</td><td>3.5003</td><td>0.0212</td><td>0.9981</td><td>0.005</td><td>0.9936</td><td>1.1208</td><td>0.0426</td><td>11.8817</td><td>0.2048</td><td>2.3406</td><td>0.0043</td><td>4830.3506</td><td>56.4954</td><td>2.382</td><td>0.058</td><td>-0.3194</td><td>0.058</td><td>0.0803</td><td>0.022</td><td>0.0102</td><td>0.0231</td><td>0.1651</td><td>0.0262</td><td>0.086569</td><td>0.008578</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>5.307</td><td>0.4989</td><td>-0.4825</td><td>0.0</td><td>Apoor</td><td>2050254113940398976</td><td>2MASS J19232466+3652089</td><td>5.307</td></tr>\n",
              "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
              "<tr><td>12784998</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>34.0536</td><td>0.2236</td><td>3.9132</td><td>0.0264</td><td>0.9975</td><td>0.005</td><td>0.9936</td><td>1.4124</td><td>0.0582</td><td>11.9181</td><td>0.2214</td><td>2.4383</td><td>0.004</td><td>4716.2725</td><td>43.5629</td><td>2.3982</td><td>0.058</td><td>0.0163</td><td>0.058</td><td>-0.0027</td><td>0.022</td><td>-0.0848</td><td>0.0109</td><td>0.2845</td><td>0.0137</td><td>0.08903</td><td>0.001833</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.3478</td><td>0.3085</td><td>-0.2419</td><td>0.0</td><td>Apoor</td><td>2139268440716719104</td><td>2MASS J19211318+5201390</td><td>3.3478</td></tr>\n",
              "<tr><td>12785083</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>10</td><td>7</td><td>9</td><td>28.1868</td><td>0.1418</td><td>3.6217</td><td>0.0208</td><td>1.0005</td><td>0.005</td><td>0.9936</td><td>1.062</td><td>0.0389</td><td>11.3888</td><td>0.1898</td><td>2.3539</td><td>0.0036</td><td>4667.458</td><td>43.0416</td><td>2.3718</td><td>0.058</td><td>-0.0811</td><td>0.058</td><td>0.111</td><td>0.022</td><td>0.1162</td><td>0.0114</td><td>0.1623</td><td>0.0141</td><td>0.090954</td><td>0.002337</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>7.3798</td><td>0.7808</td><td>-0.8104</td><td>0.0</td><td>Arich</td><td>2139269029129367936</td><td>2MASS J19212376+5204593</td><td>7.3798</td></tr>\n",
              "<tr><td>12785250</td><td>RGB</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>8</td><td>33.052</td><td>0.1996</td><td>3.8806</td><td>0.0233</td><td>1.0322</td><td>0.005</td><td>1.001</td><td>1.2168</td><td>0.0468</td><td>11.1475</td><td>0.1929</td><td>2.4285</td><td>0.0044</td><td>4784.141</td><td>54.5634</td><td>2.4946</td><td>0.058</td><td>-0.3854</td><td>0.058</td><td>0.0774</td><td>0.022</td><td>0.0512</td><td>0.023</td><td>0.1515</td><td>0.026</td><td>0.082623</td><td>0.003763</td><td>RGB</td><td>4.4587</td><td>0.5163</td><td>-0.4558</td><td>4.4587</td><td>0.5163</td><td>-0.4558</td><td>0.0</td><td>Apoor</td><td>2139269574588790400</td><td>2MASS J19214766+5205365</td><td>4.4587</td></tr>\n",
              "<tr><td>12785401</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>5</td><td>3</td><td>2</td><td>15.9445</td><td>0.6038</td><td>2.2933</td><td>0.106</td><td>1.0492</td><td>0.005</td><td>1.0221</td><td>0.9582</td><td>0.2093</td><td>14.4591</td><td>1.4539</td><td>2.0897</td><td>0.0164</td><td>4319.34</td><td>37.8322</td><td>2.1878</td><td>0.058</td><td>0.2022</td><td>0.058</td><td>0.0451</td><td>0.022</td><td>0.0492</td><td>0.0081</td><td>0.2587</td><td>0.0101</td><td>0.042488</td><td>0.004795</td><td>RGB_AGB</td><td>15.6194</td><td>22.9696</td><td>-8.2623</td><td>11.4791</td><td>9.5467</td><td>-4.6335</td><td>0.0</td><td>Apoor</td><td>2139266383430424704</td><td>2MASS J19221167+5202332</td><td>15.6194</td></tr>\n",
              "<tr><td>12833300</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>29.7501</td><td>0.1953</td><td>3.7547</td><td>0.0253</td><td>1.0</td><td>0.005</td><td>0.9936</td><td>1.057</td><td>0.0437</td><td>11.1049</td><td>0.2067</td><td>2.3738</td><td>0.004</td><td>4592.0396</td><td>41.4076</td><td>2.3874</td><td>0.058</td><td>0.0764</td><td>0.058</td><td>0.0741</td><td>0.022</td><td>0.0955</td><td>0.0097</td><td>0.19</td><td>0.0123</td><td>0.092623</td><td>0.00185</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>8.1186</td><td>0.9279</td><td>-0.877</td><td>0.0</td><td>Arich</td><td>2139492607946187648</td><td>2MASS J19171503+5207238</td><td>8.1186</td></tr>\n",
              "<tr><td>12884116</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>8</td><td>50.7865</td><td>0.3067</td><td>5.3917</td><td>0.0323</td><td>1.0334</td><td>0.005</td><td>0.9959</td><td>1.1107</td><td>0.0428</td><td>8.6775</td><td>0.1504</td><td>2.6086</td><td>0.0038</td><td>4645.334</td><td>42.5837</td><td>2.6754</td><td>0.058</td><td>-0.0631</td><td>0.058</td><td>0.0762</td><td>0.022</td><td>-0.0168</td><td>0.0111</td><td>0.0832</td><td>0.0138</td><td>0.115544</td><td>0.002715</td><td>RGB</td><td>7.6715</td><td>1.0086</td><td>-0.7863</td><td>7.6715</td><td>1.0086</td><td>-0.7863</td><td>0.0</td><td>Apoor</td><td>2139312837795971840</td><td>2MASS J19182431+5215519</td><td>7.6715</td></tr>\n",
              "<tr><td>12884661</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>7</td><td>5</td><td>2</td><td>31.3348</td><td>0.2057</td><td>3.3249</td><td>0.0224</td><td>1.0066</td><td>0.005</td><td>0.9936</td><td>1.9154</td><td>0.0792</td><td>14.617</td><td>0.2722</td><td>2.3933</td><td>0.0041</td><td>4528.001</td><td>42.9468</td><td>2.362</td><td>0.058</td><td>0.2678</td><td>0.058</td><td>0.0227</td><td>0.022</td><td>0.0588</td><td>0.0102</td><td>0.1852</td><td>0.0127</td><td>0.093641</td><td>0.002865</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>1.7467</td><td>0.1161</td><td>-0.0863</td><td>0.0</td><td>Apoor</td><td>2139309298742652672</td><td>2MASS J19192222+5213103</td><td>1.7467</td></tr>\n",
              "<tr><td>12884930</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>10</td><td>37.868</td><td>0.214</td><td>4.3441</td><td>0.0275</td><td>0.9952</td><td>0.005</td><td>0.9936</td><td>1.3724</td><td>0.0531</td><td>11.0282</td><td>0.1945</td><td>2.4933</td><td>0.0041</td><td>4912.165</td><td>53.7385</td><td>2.6052</td><td>0.058</td><td>-0.1505</td><td>0.058</td><td>0.0384</td><td>0.022</td><td>-0.0195</td><td>0.0186</td><td>0.2159</td><td>0.0219</td><td>0.094262</td><td>0.003407</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.2902</td><td>0.29</td><td>-0.2246</td><td>0.0</td><td>Apoor</td><td>2139321324651126400</td><td>2MASS J19200187+5214588</td><td>3.2902</td></tr>\n",
              "<tr><td>12885196</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>16</td><td>92.436</td><td>0.6547</td><td>8.2023</td><td>0.0549</td><td>1.0245</td><td>0.005</td><td>0.9959</td><td>1.3182</td><td>0.0551</td><td>6.9858</td><td>0.1305</td><td>2.8713</td><td>0.0043</td><td>4702.0967</td><td>46.9819</td><td>2.8123</td><td>0.058</td><td>0.1631</td><td>0.058</td><td>0.0282</td><td>0.022</td><td>-0.0045</td><td>0.0125</td><td>0.3491</td><td>0.0154</td><td>0.144815</td><td>0.003531</td><td>RGB</td><td>4.9813</td><td>0.553</td><td>-0.4742</td><td>4.9813</td><td>0.553</td><td>-0.4742</td><td>0.0</td><td>Apoor</td><td>2139321977486192640</td><td>2MASS J19203926+5214210</td><td>4.9813</td></tr>\n",
              "</table></div>"
            ],
            "text/plain": [
              "<Table length=12291>\n",
              "  KIC    EvolState ESSource ...          2MASS            Age  \n",
              "                            ...                                \n",
              " int64      str7     str4   ...          str23          float64\n",
              "-------- --------- -------- ... ----------------------- -------\n",
              "  893214       RGB     Seis ... 2MASS J19245967+3638183  2.8815\n",
              " 1026180        RC     Spec ... 2MASS J19241923+3645378  3.1325\n",
              " 1026309       RGB     Seis ... 2MASS J19242636+3643594  0.5842\n",
              " 1026452        RC     Seis ... 2MASS J19243452+3647244  2.6495\n",
              " 1027110       RGB     Seis ... 2MASS J19250937+3644599  9.0694\n",
              " 1027337       RGB     Seis ... 2MASS J19252021+3647118  5.8519\n",
              " 1027707       RGB     Seis ... 2MASS J19253846+3646103  1.3052\n",
              " 1160655       RGB     Seis ... 2MASS J19232193+3650379  5.7073\n",
              " 1160684        RC     Spec ... 2MASS J19232466+3652089   5.307\n",
              "     ...       ...      ... ...                     ...     ...\n",
              "12784998        RC     Seis ... 2MASS J19211318+5201390  3.3478\n",
              "12785083        RC     Seis ... 2MASS J19212376+5204593  7.3798\n",
              "12785250       RGB     Spec ... 2MASS J19214766+5205365  4.4587\n",
              "12785401       RGB     Seis ... 2MASS J19221167+5202332 15.6194\n",
              "12833300        RC     Seis ... 2MASS J19171503+5207238  8.1186\n",
              "12884116       RGB     Seis ... 2MASS J19182431+5215519  7.6715\n",
              "12884661        RC     Spec ... 2MASS J19192222+5213103  1.7467\n",
              "12884930        RC     Seis ... 2MASS J19200187+5214588  3.2902\n",
              "12885196       RGB     Seis ... 2MASS J19203926+5214210  4.9813"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Age option 3 APOKASC-3 Pinsonneault et al. 2025\n",
        "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
        "# and that every star in the table has an Age\n",
        "apokasc3raw= Table.read(\"Pinsonneault2025.txt\", format=\"ascii.cds\")\n",
        "#in this case there were two age columns, one for Red Clump and one for Red Giant Branch so we combine them\n",
        "ageRC=np.array(apokasc3raw['AgeRC']*(apokasc3raw['EvolState']=='RC'))\n",
        "rcnans=np.isnan(ageRC) #removing nans from this version of the table.\n",
        "ageRC[rcnans]=0\n",
        "ageRGB=np.array(apokasc3raw['AgeRGB']*(apokasc3raw['EvolState']=='RGB'))\n",
        "rgbnans=np.isnan(ageRGB) #removing nans from this version of the table.\n",
        "ageRGB[rgbnans]=0\n",
        "apokasc3raw['Age']=(ageRC+ageRGB)\n",
        "\n",
        "hasagea3=np.where((apokasc3raw['Age']==apokasc3raw['Age']) & (apokasc3raw['Age']>0.1))\n",
        "apokasc3=apokasc3raw[hasagea3]\n",
        "apokasc3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a4214dd6-940b-4f89-9091-e33337955724",
      "metadata": {
        "id": "a4214dd6-940b-4f89-9091-e33337955724"
      },
      "outputs": [],
      "source": [
        "# # Age option 4 K2 data Warfield et al. 2024\n",
        "# #Reading in the table, making sure all the tables have a column named Age in Gyr\n",
        "# # and that every star in the table has an Age\n",
        "# apok2raw = Table.read(\"Warfield2024.txt\", format=\"ascii.cds\")\n",
        "# #this one has an age column in Gyr already so we're just going to rename it Age\n",
        "# hasageapok2=np.where((apok2raw['Age']==apok2raw['Age']) & (apok2raw['Age']>0.1))\n",
        "# apok2=apok2raw[hasageapok2]\n",
        "# apok2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "135c6c2b-b3f4-48e8-b50b-a07883191546",
      "metadata": {
        "id": "135c6c2b-b3f4-48e8-b50b-a07883191546"
      },
      "outputs": [],
      "source": [
        "#My initial pick for training set\n",
        "agedata= apokasc3\n",
        "agedata2= tess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f927d0ef-3328-443f-9d1d-683402672d21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f927d0ef-3328-443f-9d1d-683402672d21",
        "outputId": "5edeff8d-1a01-4fe3-fca5-3d911e7b8082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11030 15517\n"
          ]
        }
      ],
      "source": [
        "#Option 1 TESS Theodoridis et al. 2025\n",
        "intersect2, ind_a2, ind_b2 = np.intersect1d(data_masked['tic_v8_id'],agedata2['TIC'], return_indices=True)\n",
        "\n",
        "#Option 2 APOKASC-2 Pinsonneault et al. 2018\n",
        "#intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['2MASS'], return_indices=True)\n",
        "\n",
        "#Option 3 APOKASC-3 Pinsonneault et al. 2025\n",
        "intersect, ind_a, ind_b = np.intersect1d(data_masked['gaia_dr3_source_id'],agedata['GaiaDR3'], return_indices=True)\n",
        "\n",
        "#Option 4 APO-K2 Warfield et al. 2024\n",
        "#intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['APOGEE'], return_indices=True)\n",
        "\n",
        "print(len(ind_b), len(ind_b2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9be3eb51-5d32-448b-a392-89487b460ac2",
      "metadata": {
        "id": "9be3eb51-5d32-448b-a392-89487b460ac2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "21a705e5-d564-47dd-84ec-e4192228caf9",
      "metadata": {
        "id": "21a705e5-d564-47dd-84ec-e4192228caf9"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "640d1412-8db3-45b1-b697-20eec53a4b6c",
      "metadata": {
        "id": "640d1412-8db3-45b1-b697-20eec53a4b6c"
      },
      "source": [
        "## First Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a67d4f1a-b90f-4121-a81b-afd299661f40",
      "metadata": {
        "id": "a67d4f1a-b90f-4121-a81b-afd299661f40"
      },
      "outputs": [],
      "source": [
        "fullx = np.dstack([data_masked['teff'][ind_a],data_masked['logg'][ind_a], data_masked['m_h_atm'][ind_a],\n",
        "                   data_masked['alpha_m_atm'][ind_a], data_masked['c_h'][ind_a], data_masked['n_h'][ind_a]])[0]\n",
        "\n",
        "fully = np.dstack([agedata['Age'][ind_b]])[0] #for Pinsonneault 2018\n",
        "\n",
        "#remove non-finite entries!\n",
        "mask = np.all(np.isfinite(fullx), axis=1) & np.all(np.isfinite(fully), axis=1)\n",
        "fullx, fully = fullx[mask], fully[mask]\n",
        "\n",
        "scaling_x = np.median(fullx, axis=0)\n",
        "scaling_y = np.median(fully, axis=0)\n",
        "\n",
        "fullx, fully = fullx/scaling_x, fully/scaling_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d16572b8-0b68-48aa-8154-52134dea03f4",
      "metadata": {
        "id": "d16572b8-0b68-48aa-8154-52134dea03f4"
      },
      "outputs": [],
      "source": [
        "neurons_per_layer=20\n",
        "layers=5\n",
        "iterations=200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "02a8d619-e578-425a-aa24-feb2e5b705a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "02a8d619-e578-425a-aa24-feb2e5b705a6",
        "outputId": "9f6f4cdd-4e1b-4135-9a8f-f48bde266ef6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"test\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"test\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m140\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,841</span> (7.19 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,841\u001b[0m (7.19 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,841</span> (7.19 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,841\u001b[0m (7.19 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "#start with an input layer\n",
        "inputs = keras.Input(shape=(6,))\n",
        "#now we add the Dense layers (indicating the previous layer in the brackets following the layer declaration\n",
        "\n",
        "#change this part if you're changing the number of layers\n",
        "layer1 =keras.layers.Dense(neurons_per_layer, activation='relu')(inputs)\n",
        "layer2 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer1)\n",
        "layer3 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer2)\n",
        "layer4 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer3)\n",
        "layer5 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer4)\n",
        "\n",
        "#then the output layer YOU ALSO HAVE TO MAKE THIS MATCH YOUR NUMBER OF LAYERS\n",
        "outputs = keras.layers.Dense(1)(layer5)\n",
        "\n",
        "# then we put that all together in the Model object\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='test')\n",
        "#and we can print a summary to check it all went to plan\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b49f6c53-d915-4af4-9a1b-9fe2151140ab",
      "metadata": {
        "id": "b49f6c53-d915-4af4-9a1b-9fe2151140ab"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4dbbfa16-1d2c-4204-9cbd-592fcb53d122",
      "metadata": {
        "id": "4dbbfa16-1d2c-4204-9cbd-592fcb53d122"
      },
      "outputs": [],
      "source": [
        "tenpercent=len(agedata['Age'][ind_b])//10 #figure out what ten percent of this set of age data is\n",
        "\n",
        "#last name before M\n",
        "#trainbin=slice(0,-1*tenpercent-1)\n",
        "#testing=slice(-1*tenpercent,-1)\n",
        "\n",
        "\n",
        "#last name M or later\n",
        "trainbin=slice(tenpercent+1,-1)\n",
        "testing=slice(0,tenpercent)\n",
        "\n",
        "\n",
        "x_train, y_train = fullx[trainbin], fully[trainbin]\n",
        "x_test, y_test = fullx[testing], fully[testing]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ed78eb61-fae5-4e7c-a84b-5a149a9e2486",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed78eb61-fae5-4e7c-a84b-5a149a9e2486",
        "outputId": "d7fa9887-61c2-4353-b010-7be67f934175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 1.6555 - val_accuracy: 0.0000e+00 - val_loss: 0.7498\n",
            "Epoch 2/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.9548 - val_accuracy: 0.0000e+00 - val_loss: 0.5811\n",
            "Epoch 3/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.8484 - val_accuracy: 0.0000e+00 - val_loss: 0.5001\n",
            "Epoch 4/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.7650 - val_accuracy: 0.0000e+00 - val_loss: 0.4380\n",
            "Epoch 5/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.7072 - val_accuracy: 0.0000e+00 - val_loss: 0.4064\n",
            "Epoch 6/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.6737 - val_accuracy: 0.0000e+00 - val_loss: 0.3901\n",
            "Epoch 7/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.6458 - val_accuracy: 0.0000e+00 - val_loss: 0.3685\n",
            "Epoch 8/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.6259 - val_accuracy: 0.0000e+00 - val_loss: 0.3611\n",
            "Epoch 9/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.6100 - val_accuracy: 0.0000e+00 - val_loss: 0.3510\n",
            "Epoch 10/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5990 - val_accuracy: 0.0000e+00 - val_loss: 0.3507\n",
            "Epoch 11/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5942 - val_accuracy: 0.0000e+00 - val_loss: 0.3390\n",
            "Epoch 12/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5832 - val_accuracy: 0.0000e+00 - val_loss: 0.3418\n",
            "Epoch 13/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5765 - val_accuracy: 0.0000e+00 - val_loss: 0.3529\n",
            "Epoch 14/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5730 - val_accuracy: 0.0000e+00 - val_loss: 0.3291\n",
            "Epoch 15/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5724 - val_accuracy: 0.0000e+00 - val_loss: 0.3649\n",
            "Epoch 16/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.1391e-04 - loss: 0.5708 - val_accuracy: 0.0000e+00 - val_loss: 0.3402\n",
            "Epoch 17/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5643 - val_accuracy: 0.0000e+00 - val_loss: 0.3259\n",
            "Epoch 18/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5638 - val_accuracy: 0.0000e+00 - val_loss: 0.3351\n",
            "Epoch 19/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5636 - val_accuracy: 0.0000e+00 - val_loss: 0.3343\n",
            "Epoch 20/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5628 - val_accuracy: 0.0000e+00 - val_loss: 0.3226\n",
            "Epoch 21/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5599 - val_accuracy: 0.0000e+00 - val_loss: 0.3151\n",
            "Epoch 22/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5583 - val_accuracy: 0.0000e+00 - val_loss: 0.3171\n",
            "Epoch 23/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5605 - val_accuracy: 0.0000e+00 - val_loss: 0.3213\n",
            "Epoch 24/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5567 - val_accuracy: 0.0000e+00 - val_loss: 0.3267\n",
            "Epoch 25/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5549 - val_accuracy: 0.0000e+00 - val_loss: 0.3175\n",
            "Epoch 26/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5545 - val_accuracy: 0.0000e+00 - val_loss: 0.3209\n",
            "Epoch 27/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5570 - val_accuracy: 0.0000e+00 - val_loss: 0.3164\n",
            "Epoch 28/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5530 - val_accuracy: 0.0000e+00 - val_loss: 0.3201\n",
            "Epoch 29/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5513 - val_accuracy: 0.0000e+00 - val_loss: 0.3178\n",
            "Epoch 30/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5526 - val_accuracy: 0.0000e+00 - val_loss: 0.3204\n",
            "Epoch 31/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5531 - val_accuracy: 0.0000e+00 - val_loss: 0.3130\n",
            "Epoch 32/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5496 - val_accuracy: 0.0000e+00 - val_loss: 0.3372\n",
            "Epoch 33/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5516 - val_accuracy: 0.0000e+00 - val_loss: 0.3245\n",
            "Epoch 34/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5547 - val_accuracy: 0.0000e+00 - val_loss: 0.3232\n",
            "Epoch 35/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5516 - val_accuracy: 0.0000e+00 - val_loss: 0.3083\n",
            "Epoch 36/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5484 - val_accuracy: 0.0000e+00 - val_loss: 0.3111\n",
            "Epoch 37/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5444 - val_accuracy: 0.0000e+00 - val_loss: 0.3042\n",
            "Epoch 38/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5432 - val_accuracy: 0.0000e+00 - val_loss: 0.3094\n",
            "Epoch 39/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5491 - val_accuracy: 0.0000e+00 - val_loss: 0.3000\n",
            "Epoch 40/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5467 - val_accuracy: 0.0000e+00 - val_loss: 0.3159\n",
            "Epoch 41/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5442 - val_accuracy: 0.0000e+00 - val_loss: 0.3070\n",
            "Epoch 42/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5441 - val_accuracy: 0.0000e+00 - val_loss: 0.3054\n",
            "Epoch 43/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5407 - val_accuracy: 0.0000e+00 - val_loss: 0.3049\n",
            "Epoch 44/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5401 - val_accuracy: 0.0000e+00 - val_loss: 0.3219\n",
            "Epoch 45/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5422 - val_accuracy: 0.0000e+00 - val_loss: 0.3085\n",
            "Epoch 46/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5424 - val_accuracy: 0.0000e+00 - val_loss: 0.2961\n",
            "Epoch 47/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5424 - val_accuracy: 0.0000e+00 - val_loss: 0.2930\n",
            "Epoch 48/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5390 - val_accuracy: 0.0000e+00 - val_loss: 0.3069\n",
            "Epoch 49/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5419 - val_accuracy: 0.0000e+00 - val_loss: 0.3077\n",
            "Epoch 50/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5409 - val_accuracy: 0.0000e+00 - val_loss: 0.3015\n",
            "Epoch 51/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5447 - val_accuracy: 0.0000e+00 - val_loss: 0.2969\n",
            "Epoch 52/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5362 - val_accuracy: 0.0000e+00 - val_loss: 0.2932\n",
            "Epoch 53/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5450 - val_accuracy: 0.0000e+00 - val_loss: 0.2871\n",
            "Epoch 54/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5364 - val_accuracy: 0.0000e+00 - val_loss: 0.2916\n",
            "Epoch 55/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5405 - val_accuracy: 0.0000e+00 - val_loss: 0.2964\n",
            "Epoch 56/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5354 - val_accuracy: 0.0000e+00 - val_loss: 0.2911\n",
            "Epoch 57/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5361 - val_accuracy: 0.0000e+00 - val_loss: 0.2976\n",
            "Epoch 58/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5349 - val_accuracy: 0.0000e+00 - val_loss: 0.3009\n",
            "Epoch 59/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5410 - val_accuracy: 0.0000e+00 - val_loss: 0.3001\n",
            "Epoch 60/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5410 - val_accuracy: 0.0000e+00 - val_loss: 0.3111\n",
            "Epoch 61/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5340 - val_accuracy: 0.0000e+00 - val_loss: 0.2893\n",
            "Epoch 62/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.2937\n",
            "Epoch 63/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5346 - val_accuracy: 0.0000e+00 - val_loss: 0.2869\n",
            "Epoch 64/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5321 - val_accuracy: 0.0000e+00 - val_loss: 0.2977\n",
            "Epoch 65/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5291 - val_accuracy: 0.0000e+00 - val_loss: 0.2938\n",
            "Epoch 66/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.2985\n",
            "Epoch 67/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5333 - val_accuracy: 0.0000e+00 - val_loss: 0.2899\n",
            "Epoch 68/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 0.3156\n",
            "Epoch 69/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5366 - val_accuracy: 0.0000e+00 - val_loss: 0.3076\n",
            "Epoch 70/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.2861\n",
            "Epoch 71/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.2838\n",
            "Epoch 72/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.2869\n",
            "Epoch 73/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 0.2915\n",
            "Epoch 74/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5355 - val_accuracy: 0.0000e+00 - val_loss: 0.2956\n",
            "Epoch 75/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5365 - val_accuracy: 0.0000e+00 - val_loss: 0.2916\n",
            "Epoch 76/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5337 - val_accuracy: 0.0000e+00 - val_loss: 0.2887\n",
            "Epoch 77/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 0.2961\n",
            "Epoch 78/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 0.2846\n",
            "Epoch 79/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.3130\n",
            "Epoch 80/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5337 - val_accuracy: 0.0000e+00 - val_loss: 0.2996\n",
            "Epoch 81/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5271 - val_accuracy: 0.0000e+00 - val_loss: 0.2852\n",
            "Epoch 82/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5289 - val_accuracy: 0.0000e+00 - val_loss: 0.2833\n",
            "Epoch 83/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5281 - val_accuracy: 0.0000e+00 - val_loss: 0.2936\n",
            "Epoch 84/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5277 - val_accuracy: 0.0000e+00 - val_loss: 0.2843\n",
            "Epoch 85/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.2865\n",
            "Epoch 86/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5323 - val_accuracy: 0.0000e+00 - val_loss: 0.2902\n",
            "Epoch 87/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5263 - val_accuracy: 0.0000e+00 - val_loss: 0.2855\n",
            "Epoch 88/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5258 - val_accuracy: 0.0000e+00 - val_loss: 0.2879\n",
            "Epoch 89/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5246 - val_accuracy: 0.0000e+00 - val_loss: 0.2905\n",
            "Epoch 90/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5245 - val_accuracy: 0.0000e+00 - val_loss: 0.2805\n",
            "Epoch 91/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5287 - val_accuracy: 0.0000e+00 - val_loss: 0.2879\n",
            "Epoch 92/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 0.2863\n",
            "Epoch 93/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5269 - val_accuracy: 0.0000e+00 - val_loss: 0.2898\n",
            "Epoch 94/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5280 - val_accuracy: 0.0000e+00 - val_loss: 0.3190\n",
            "Epoch 95/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5259 - val_accuracy: 0.0000e+00 - val_loss: 0.2925\n",
            "Epoch 96/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5250 - val_accuracy: 0.0000e+00 - val_loss: 0.2837\n",
            "Epoch 97/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5280 - val_accuracy: 0.0000e+00 - val_loss: 0.2898\n",
            "Epoch 98/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5254 - val_accuracy: 0.0000e+00 - val_loss: 0.2916\n",
            "Epoch 99/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5228 - val_accuracy: 0.0000e+00 - val_loss: 0.2861\n",
            "Epoch 100/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5267 - val_accuracy: 0.0000e+00 - val_loss: 0.2883\n",
            "Epoch 101/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5230 - val_accuracy: 0.0000e+00 - val_loss: 0.2875\n",
            "Epoch 102/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5229 - val_accuracy: 0.0000e+00 - val_loss: 0.2795\n",
            "Epoch 103/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5235 - val_accuracy: 0.0000e+00 - val_loss: 0.2891\n",
            "Epoch 104/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5237 - val_accuracy: 0.0000e+00 - val_loss: 0.2995\n",
            "Epoch 105/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5220 - val_accuracy: 0.0000e+00 - val_loss: 0.2894\n",
            "Epoch 106/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5229 - val_accuracy: 0.0000e+00 - val_loss: 0.2825\n",
            "Epoch 107/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5281 - val_accuracy: 0.0000e+00 - val_loss: 0.2816\n",
            "Epoch 108/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5241 - val_accuracy: 0.0000e+00 - val_loss: 0.2917\n",
            "Epoch 109/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5280 - val_accuracy: 0.0000e+00 - val_loss: 0.2854\n",
            "Epoch 110/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5230 - val_accuracy: 0.0000e+00 - val_loss: 0.2909\n",
            "Epoch 111/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5221 - val_accuracy: 0.0000e+00 - val_loss: 0.2843\n",
            "Epoch 112/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5197 - val_accuracy: 0.0000e+00 - val_loss: 0.2932\n",
            "Epoch 113/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5203 - val_accuracy: 0.0000e+00 - val_loss: 0.2820\n",
            "Epoch 114/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5261 - val_accuracy: 0.0000e+00 - val_loss: 0.2840\n",
            "Epoch 115/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5212 - val_accuracy: 0.0000e+00 - val_loss: 0.2819\n",
            "Epoch 116/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5214 - val_accuracy: 0.0000e+00 - val_loss: 0.2812\n",
            "Epoch 117/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5248 - val_accuracy: 0.0000e+00 - val_loss: 0.3000\n",
            "Epoch 118/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5202 - val_accuracy: 0.0000e+00 - val_loss: 0.2900\n",
            "Epoch 119/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5216 - val_accuracy: 0.0000e+00 - val_loss: 0.2791\n",
            "Epoch 120/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5234 - val_accuracy: 0.0000e+00 - val_loss: 0.2824\n",
            "Epoch 121/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5213 - val_accuracy: 0.0000e+00 - val_loss: 0.2905\n",
            "Epoch 122/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5194 - val_accuracy: 0.0000e+00 - val_loss: 0.2919\n",
            "Epoch 123/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5189 - val_accuracy: 0.0000e+00 - val_loss: 0.2762\n",
            "Epoch 124/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5186 - val_accuracy: 0.0000e+00 - val_loss: 0.2921\n",
            "Epoch 125/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5196 - val_accuracy: 0.0000e+00 - val_loss: 0.2846\n",
            "Epoch 126/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5170 - val_accuracy: 0.0000e+00 - val_loss: 0.2909\n",
            "Epoch 127/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5203 - val_accuracy: 0.0000e+00 - val_loss: 0.2848\n",
            "Epoch 128/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5236 - val_accuracy: 0.0000e+00 - val_loss: 0.2767\n",
            "Epoch 129/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5173 - val_accuracy: 0.0000e+00 - val_loss: 0.2833\n",
            "Epoch 130/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5147 - val_accuracy: 0.0000e+00 - val_loss: 0.2780\n",
            "Epoch 131/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5154 - val_accuracy: 0.0000e+00 - val_loss: 0.2869\n",
            "Epoch 132/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5160 - val_accuracy: 0.0000e+00 - val_loss: 0.2791\n",
            "Epoch 133/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5228 - val_accuracy: 0.0000e+00 - val_loss: 0.2768\n",
            "Epoch 134/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5192 - val_accuracy: 0.0000e+00 - val_loss: 0.2896\n",
            "Epoch 135/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5170 - val_accuracy: 0.0000e+00 - val_loss: 0.3212\n",
            "Epoch 136/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5241 - val_accuracy: 0.0000e+00 - val_loss: 0.2998\n",
            "Epoch 137/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5241 - val_accuracy: 0.0000e+00 - val_loss: 0.2888\n",
            "Epoch 138/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5206 - val_accuracy: 0.0000e+00 - val_loss: 0.2795\n",
            "Epoch 139/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5143 - val_accuracy: 0.0000e+00 - val_loss: 0.2819\n",
            "Epoch 140/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5196 - val_accuracy: 0.0000e+00 - val_loss: 0.2818\n",
            "Epoch 141/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5187 - val_accuracy: 0.0000e+00 - val_loss: 0.2900\n",
            "Epoch 142/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5165 - val_accuracy: 0.0000e+00 - val_loss: 0.2971\n",
            "Epoch 143/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5180 - val_accuracy: 0.0000e+00 - val_loss: 0.2809\n",
            "Epoch 144/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5134 - val_accuracy: 0.0000e+00 - val_loss: 0.2792\n",
            "Epoch 145/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5145 - val_accuracy: 0.0000e+00 - val_loss: 0.2776\n",
            "Epoch 146/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5146 - val_accuracy: 0.0000e+00 - val_loss: 0.2776\n",
            "Epoch 147/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5145 - val_accuracy: 0.0000e+00 - val_loss: 0.2861\n",
            "Epoch 148/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.1391e-04 - loss: 0.5135 - val_accuracy: 0.0000e+00 - val_loss: 0.2907\n",
            "Epoch 149/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5140 - val_accuracy: 0.0000e+00 - val_loss: 0.3073\n",
            "Epoch 150/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5205 - val_accuracy: 0.0000e+00 - val_loss: 0.2902\n",
            "Epoch 151/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5160 - val_accuracy: 0.0000e+00 - val_loss: 0.3052\n",
            "Epoch 152/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5138 - val_accuracy: 0.0000e+00 - val_loss: 0.2890\n",
            "Epoch 153/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5142 - val_accuracy: 0.0000e+00 - val_loss: 0.2895\n",
            "Epoch 154/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5114 - val_accuracy: 0.0000e+00 - val_loss: 0.2955\n",
            "Epoch 155/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5170 - val_accuracy: 0.0000e+00 - val_loss: 0.3060\n",
            "Epoch 156/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5169 - val_accuracy: 0.0000e+00 - val_loss: 0.2941\n",
            "Epoch 157/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5125 - val_accuracy: 0.0000e+00 - val_loss: 0.2854\n",
            "Epoch 158/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5147 - val_accuracy: 0.0000e+00 - val_loss: 0.2893\n",
            "Epoch 159/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5143 - val_accuracy: 0.0000e+00 - val_loss: 0.2867\n",
            "Epoch 160/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5112 - val_accuracy: 0.0000e+00 - val_loss: 0.2889\n",
            "Epoch 161/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5109 - val_accuracy: 0.0000e+00 - val_loss: 0.2810\n",
            "Epoch 162/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5143 - val_accuracy: 0.0000e+00 - val_loss: 0.3005\n",
            "Epoch 163/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5129 - val_accuracy: 0.0000e+00 - val_loss: 0.2876\n",
            "Epoch 164/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5165 - val_accuracy: 0.0000e+00 - val_loss: 0.2884\n",
            "Epoch 165/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5111 - val_accuracy: 0.0000e+00 - val_loss: 0.2861\n",
            "Epoch 166/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.1391e-04 - loss: 0.5127 - val_accuracy: 0.0000e+00 - val_loss: 0.3047\n",
            "Epoch 167/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5149 - val_accuracy: 0.0000e+00 - val_loss: 0.2926\n",
            "Epoch 168/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5104 - val_accuracy: 0.0000e+00 - val_loss: 0.2930\n",
            "Epoch 169/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5092 - val_accuracy: 0.0000e+00 - val_loss: 0.2965\n",
            "Epoch 170/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5128 - val_accuracy: 0.0000e+00 - val_loss: 0.2837\n",
            "Epoch 171/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.1391e-04 - loss: 0.5120 - val_accuracy: 0.0000e+00 - val_loss: 0.2873\n",
            "Epoch 172/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5111 - val_accuracy: 0.0000e+00 - val_loss: 0.2839\n",
            "Epoch 173/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5116 - val_accuracy: 0.0000e+00 - val_loss: 0.2905\n",
            "Epoch 174/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5147 - val_accuracy: 0.0000e+00 - val_loss: 0.3104\n",
            "Epoch 175/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5146 - val_accuracy: 0.0000e+00 - val_loss: 0.2908\n",
            "Epoch 176/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5161 - val_accuracy: 0.0000e+00 - val_loss: 0.2913\n",
            "Epoch 177/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5097 - val_accuracy: 0.0000e+00 - val_loss: 0.2991\n",
            "Epoch 178/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5099 - val_accuracy: 0.0000e+00 - val_loss: 0.2830\n",
            "Epoch 179/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5098 - val_accuracy: 0.0000e+00 - val_loss: 0.3020\n",
            "Epoch 180/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5116 - val_accuracy: 0.0000e+00 - val_loss: 0.2838\n",
            "Epoch 181/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5118 - val_accuracy: 0.0000e+00 - val_loss: 0.2835\n",
            "Epoch 182/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5094 - val_accuracy: 0.0000e+00 - val_loss: 0.2850\n",
            "Epoch 183/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5102 - val_accuracy: 0.0000e+00 - val_loss: 0.2979\n",
            "Epoch 184/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5123 - val_accuracy: 0.0000e+00 - val_loss: 0.2929\n",
            "Epoch 185/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5063 - val_accuracy: 0.0000e+00 - val_loss: 0.2848\n",
            "Epoch 186/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5098 - val_accuracy: 0.0000e+00 - val_loss: 0.2847\n",
            "Epoch 187/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5146 - val_accuracy: 0.0000e+00 - val_loss: 0.3158\n",
            "Epoch 188/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5154 - val_accuracy: 0.0000e+00 - val_loss: 0.2933\n",
            "Epoch 189/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.1391e-04 - loss: 0.5100 - val_accuracy: 0.0000e+00 - val_loss: 0.3068\n",
            "Epoch 190/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5079 - val_accuracy: 0.0000e+00 - val_loss: 0.2936\n",
            "Epoch 191/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5061 - val_accuracy: 0.0000e+00 - val_loss: 0.2767\n",
            "Epoch 192/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5070 - val_accuracy: 0.0000e+00 - val_loss: 0.3083\n",
            "Epoch 193/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5128 - val_accuracy: 0.0000e+00 - val_loss: 0.2882\n",
            "Epoch 194/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5104 - val_accuracy: 0.0000e+00 - val_loss: 0.2941\n",
            "Epoch 195/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.1391e-04 - loss: 0.5061 - val_accuracy: 0.0000e+00 - val_loss: 0.2843\n",
            "Epoch 196/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5118 - val_accuracy: 0.0000e+00 - val_loss: 0.2860\n",
            "Epoch 197/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.1391e-04 - loss: 0.5083 - val_accuracy: 0.0000e+00 - val_loss: 0.2814\n",
            "Epoch 198/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.1391e-04 - loss: 0.5061 - val_accuracy: 0.0000e+00 - val_loss: 0.2904\n",
            "Epoch 199/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5095 - val_accuracy: 0.0000e+00 - val_loss: 0.2983\n",
            "Epoch 200/200\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.1391e-04 - loss: 0.5060 - val_accuracy: 0.0000e+00 - val_loss: 0.2859\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1a20f025040>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=iterations, validation_split=0.05, batch_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b9945274-b190-45b2-954c-5e681f461a59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9945274-b190-45b2-954c-5e681f461a59",
        "outputId": "c137b0f9-27dd-42a8-9357-6512967ad8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "1103\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "print(len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6133233a-176f-49b3-8768-75f30fc38369",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6133233a-176f-49b3-8768-75f30fc38369",
        "outputId": "1eededf6-bdbd-4842-e887-0238d58c6307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "425631\n",
            "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "DR19x = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
        "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
        "print(len(data_masked['teff']))\n",
        "\n",
        "DR19x= DR19x/scaling_x\n",
        "predictionsDR19 = model.predict(DR19x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f799fc4d-9d03-422d-8658-825852967a4a",
      "metadata": {
        "id": "f799fc4d-9d03-422d-8658-825852967a4a"
      },
      "source": [
        "## Training Set 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "82c3b69f-6967-45dd-ba85-0a09732fb03b",
      "metadata": {
        "id": "82c3b69f-6967-45dd-ba85-0a09732fb03b"
      },
      "outputs": [],
      "source": [
        "fullx2 = np.dstack([data_masked['teff'][ind_a2],data_masked['logg'][ind_a2], data_masked['m_h_atm'][ind_a2],\n",
        "                   data_masked['alpha_m_atm'][ind_a2], data_masked['c_h'][ind_a2], data_masked['n_h'][ind_a2]])[0]\n",
        "\n",
        "fully2 = np.dstack([agedata2['Age'][ind_b2]])[0] #for Pinsonneault 2018\n",
        "\n",
        "#remove non-finite entries!\n",
        "mask2 = np.all(np.isfinite(fullx2), axis=1) & np.all(np.isfinite(fully2), axis=1)\n",
        "fullx2, fully2 = fullx2[mask2], fully2[mask2]\n",
        "\n",
        "scaling_x2 = np.median(fullx2, axis=0)\n",
        "scaling_y2 = np.median(fully2, axis=0)\n",
        "fullx2, fully2 = fullx2/scaling_x2, fully2/scaling_y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "15087510-3a8e-48a9-87c4-8d82826cfdd7",
      "metadata": {
        "id": "15087510-3a8e-48a9-87c4-8d82826cfdd7"
      },
      "outputs": [],
      "source": [
        "tenpercent2=len(agedata2['Age'][ind_b2])//10 #figure out what ten percent of this set of age data is\n",
        "\n",
        "#last name before M\n",
        "#trainbin=slice(0,-1*tenpercent-1)\n",
        "#testing=slice(-1*tenpercent,-1)\n",
        "\n",
        "\n",
        "#last name M or later\n",
        "trainbin2=slice(tenpercent2+1,-1)\n",
        "testing2=slice(0,tenpercent2)\n",
        "\n",
        "\n",
        "x_train2, y_train2 = fullx2[trainbin2], fully2[trainbin2]\n",
        "x_test2, y_test2 = fullx2[testing2], fully2[testing2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ae47b020-77bc-4dc3-ad7c-9ff72cd1231d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae47b020-77bc-4dc3-ad7c-9ff72cd1231d",
        "outputId": "8af751d6-25b0-48cc-cfff-37b4a4624340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.4048 - val_accuracy: 0.0000e+00 - val_loss: 0.2060\n",
            "Epoch 2/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.2153 - val_accuracy: 0.0000e+00 - val_loss: 0.1929\n",
            "Epoch 3/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.2012 - val_accuracy: 0.0000e+00 - val_loss: 0.1858\n",
            "Epoch 4/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1954 - val_accuracy: 0.0000e+00 - val_loss: 0.1842\n",
            "Epoch 5/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1921 - val_accuracy: 0.0000e+00 - val_loss: 0.1861\n",
            "Epoch 6/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1909 - val_accuracy: 0.0000e+00 - val_loss: 0.1830\n",
            "Epoch 7/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1903 - val_accuracy: 0.0000e+00 - val_loss: 0.1863\n",
            "Epoch 8/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1896 - val_accuracy: 0.0000e+00 - val_loss: 0.1842\n",
            "Epoch 9/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1884 - val_accuracy: 0.0000e+00 - val_loss: 0.1845\n",
            "Epoch 10/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1876 - val_accuracy: 0.0000e+00 - val_loss: 0.1842\n",
            "Epoch 11/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1876 - val_accuracy: 0.0000e+00 - val_loss: 0.1818\n",
            "Epoch 12/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1875 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
            "Epoch 13/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 14/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 15/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1861 - val_accuracy: 0.0000e+00 - val_loss: 0.1822\n",
            "Epoch 16/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
            "Epoch 17/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1856 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
            "Epoch 18/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1856 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 19/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1854 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
            "Epoch 20/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1849 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
            "Epoch 21/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 7.9917e-05 - loss: 0.1846 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n",
            "Epoch 22/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1847 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 23/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1848 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
            "Epoch 24/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1829\n",
            "Epoch 25/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1843 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
            "Epoch 26/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
            "Epoch 27/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1839 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
            "Epoch 28/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1843 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
            "Epoch 29/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1855\n",
            "Epoch 30/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 31/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1842 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
            "Epoch 32/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1839 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
            "Epoch 33/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1837 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
            "Epoch 34/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1840 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 35/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1833 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
            "Epoch 36/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1838 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 37/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1830 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 38/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1829 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 39/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1840 - val_accuracy: 0.0000e+00 - val_loss: 0.1824\n",
            "Epoch 40/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1830 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n",
            "Epoch 41/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1831 - val_accuracy: 0.0000e+00 - val_loss: 0.1824\n",
            "Epoch 42/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1825 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
            "Epoch 43/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1829 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 44/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1827 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
            "Epoch 45/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1815 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
            "Epoch 46/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
            "Epoch 47/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1821 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 48/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1823 - val_accuracy: 0.0000e+00 - val_loss: 0.1834\n",
            "Epoch 49/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1819 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
            "Epoch 50/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
            "Epoch 51/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 52/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1817 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
            "Epoch 53/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1812 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
            "Epoch 54/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 55/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1813 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
            "Epoch 56/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1815 - val_accuracy: 0.0000e+00 - val_loss: 0.1853\n",
            "Epoch 57/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1814 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 58/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1834\n",
            "Epoch 59/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1818 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
            "Epoch 60/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
            "Epoch 61/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
            "Epoch 62/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1808 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
            "Epoch 63/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1808 - val_accuracy: 0.0000e+00 - val_loss: 0.1847\n",
            "Epoch 64/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1840\n",
            "Epoch 65/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1802 - val_accuracy: 0.0000e+00 - val_loss: 0.1843\n",
            "Epoch 66/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1827\n",
            "Epoch 67/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
            "Epoch 68/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1803 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
            "Epoch 69/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1802 - val_accuracy: 0.0000e+00 - val_loss: 0.1852\n",
            "Epoch 70/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1801 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
            "Epoch 71/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1794 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
            "Epoch 72/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1799 - val_accuracy: 0.0000e+00 - val_loss: 0.1799\n",
            "Epoch 73/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1820\n",
            "Epoch 74/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1798 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 75/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1801 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 76/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
            "Epoch 77/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 78/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1803 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
            "Epoch 79/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1820\n",
            "Epoch 80/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
            "Epoch 81/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1794 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 82/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1833\n",
            "Epoch 83/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1792 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 84/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
            "Epoch 85/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1822\n",
            "Epoch 86/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1803 - val_accuracy: 0.0000e+00 - val_loss: 0.1842\n",
            "Epoch 87/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1801 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
            "Epoch 88/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1791 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
            "Epoch 89/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1792 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
            "Epoch 90/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1795 - val_accuracy: 0.0000e+00 - val_loss: 0.1818\n",
            "Epoch 91/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
            "Epoch 92/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
            "Epoch 93/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1786 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 94/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1784 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
            "Epoch 95/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1786 - val_accuracy: 0.0000e+00 - val_loss: 0.1849\n",
            "Epoch 96/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1790 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n",
            "Epoch 97/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1794 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
            "Epoch 98/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1792 - val_accuracy: 0.0000e+00 - val_loss: 0.1832\n",
            "Epoch 99/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 100/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1791 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
            "Epoch 101/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1786 - val_accuracy: 0.0000e+00 - val_loss: 0.1843\n",
            "Epoch 102/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1783 - val_accuracy: 0.0000e+00 - val_loss: 0.1818\n",
            "Epoch 103/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1831\n",
            "Epoch 104/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1784 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
            "Epoch 105/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1788 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
            "Epoch 106/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1782 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 107/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
            "Epoch 108/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
            "Epoch 109/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1843\n",
            "Epoch 110/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 111/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1776 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
            "Epoch 112/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1787 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 113/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1777 - val_accuracy: 0.0000e+00 - val_loss: 0.1782\n",
            "Epoch 114/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1829\n",
            "Epoch 115/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1776 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 116/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1780 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n",
            "Epoch 117/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 118/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
            "Epoch 119/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1797\n",
            "Epoch 120/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 121/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
            "Epoch 122/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1789 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
            "Epoch 123/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1776 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
            "Epoch 124/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
            "Epoch 125/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1777 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
            "Epoch 126/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1829\n",
            "Epoch 127/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
            "Epoch 128/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1774 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 129/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1765 - val_accuracy: 0.0000e+00 - val_loss: 0.1827\n",
            "Epoch 130/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1782 - val_accuracy: 0.0000e+00 - val_loss: 0.1860\n",
            "Epoch 131/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1830\n",
            "Epoch 132/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1773 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
            "Epoch 133/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1770 - val_accuracy: 0.0000e+00 - val_loss: 0.1875\n",
            "Epoch 134/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1773 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 135/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1769 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 136/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
            "Epoch 137/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1829\n",
            "Epoch 138/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1761 - val_accuracy: 0.0000e+00 - val_loss: 0.1836\n",
            "Epoch 139/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1770 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
            "Epoch 140/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
            "Epoch 141/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1766 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
            "Epoch 142/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 143/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1773 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
            "Epoch 144/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1764 - val_accuracy: 0.0000e+00 - val_loss: 0.1809\n",
            "Epoch 145/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1868\n",
            "Epoch 146/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1759 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
            "Epoch 147/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1759 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
            "Epoch 148/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1767 - val_accuracy: 0.0000e+00 - val_loss: 0.1822\n",
            "Epoch 149/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1793\n",
            "Epoch 150/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
            "Epoch 151/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1886\n",
            "Epoch 152/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1765 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
            "Epoch 153/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1761 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 154/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1763 - val_accuracy: 0.0000e+00 - val_loss: 0.1809\n",
            "Epoch 155/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1758 - val_accuracy: 0.0000e+00 - val_loss: 0.1785\n",
            "Epoch 156/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
            "Epoch 157/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1754 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
            "Epoch 158/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1766 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
            "Epoch 159/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1765 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
            "Epoch 160/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
            "Epoch 161/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1755 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
            "Epoch 162/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1757 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
            "Epoch 163/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1758 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
            "Epoch 164/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1755 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
            "Epoch 165/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1757 - val_accuracy: 0.0000e+00 - val_loss: 0.1833\n",
            "Epoch 166/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1753 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
            "Epoch 167/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1755 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 168/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 169/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1747 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
            "Epoch 170/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1757 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
            "Epoch 171/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1750 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 172/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1746 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
            "Epoch 173/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1757 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
            "Epoch 174/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1750 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
            "Epoch 175/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1751 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
            "Epoch 176/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1753 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
            "Epoch 177/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1752 - val_accuracy: 0.0000e+00 - val_loss: 0.1866\n",
            "Epoch 178/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1759 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
            "Epoch 179/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1753 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
            "Epoch 180/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1756 - val_accuracy: 0.0000e+00 - val_loss: 0.1797\n",
            "Epoch 181/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1751 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 182/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1753 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
            "Epoch 183/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1751 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
            "Epoch 184/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1749 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
            "Epoch 185/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1761 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
            "Epoch 186/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1743 - val_accuracy: 0.0000e+00 - val_loss: 0.1777\n",
            "Epoch 187/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1754 - val_accuracy: 0.0000e+00 - val_loss: 0.1853\n",
            "Epoch 188/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1749 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 189/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1750 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
            "Epoch 190/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1749 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
            "Epoch 191/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1750 - val_accuracy: 0.0000e+00 - val_loss: 0.1820\n",
            "Epoch 192/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1748 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
            "Epoch 193/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1746 - val_accuracy: 0.0000e+00 - val_loss: 0.1777\n",
            "Epoch 194/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 7.9917e-05 - loss: 0.1749 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
            "Epoch 195/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1743 - val_accuracy: 0.0000e+00 - val_loss: 0.1834\n",
            "Epoch 196/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1747 - val_accuracy: 0.0000e+00 - val_loss: 0.1856\n",
            "Epoch 197/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1744 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
            "Epoch 198/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 7.9917e-05 - loss: 0.1746 - val_accuracy: 0.0000e+00 - val_loss: 0.1859\n",
            "Epoch 199/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 7.9917e-05 - loss: 0.1740 - val_accuracy: 0.0000e+00 - val_loss: 0.1827\n",
            "Epoch 200/200\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.9917e-05 - loss: 0.1742 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1a210e8aae0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train2, y_train2, epochs=iterations, validation_split=0.05, batch_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "40eef300-0aa6-4982-8d70-9f7c9725771a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40eef300-0aa6-4982-8d70-9f7c9725771a",
        "outputId": "2e8a22ff-50c4-4d37-9a2e-808deebe1c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "1551\n"
          ]
        }
      ],
      "source": [
        "predictions2 = model.predict(x_test2)\n",
        "print(len(predictions2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e203510c-d93e-49b0-82f1-e6cb7b251417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e203510c-d93e-49b0-82f1-e6cb7b251417",
        "outputId": "e1adbcf2-4040-4086-c1a5-64324810b487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "425631\n",
            "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "DR19x2 = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
        "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
        "print(len(data_masked['teff']))\n",
        "\n",
        "DR19x2= DR19x2/scaling_x2\n",
        "predictionsDR19_2 = model.predict(DR19x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7c82f539-21c2-4d83-a2bb-ff8aaccbba77",
      "metadata": {
        "id": "7c82f539-21c2-4d83-a2bb-ff8aaccbba77"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Pulling Labels and Data\n",
        "apokasc3_age = predictionsDR19.flatten()\n",
        "tess_age = predictionsDR19_2.flatten()\n",
        "age_difference = tess_age - apokasc3_age\n",
        "star_ids = data_masked['tic_v8_id']\n",
        "#Creating DataFrame of the results\n",
        "dataframe = pd.DataFrame({\n",
        "\t\"TIC\": star_ids,\n",
        "\t'TESS_predicted_Gyr': tess_age,\n",
        "\t'APOKASC3_predicted_Gyr': apokasc3_age,\n",
        "    'TESS_APOKASC3_Diff': age_difference\n",
        "})\n",
        "#Saving DataFrame to CSV\n",
        "dataframe.to_csv('TESS_APOKASC3_Comparison.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "99d43871-b400-4d2c-8dc3-8dfca1296571",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99d43871-b400-4d2c-8dc3-8dfca1296571",
        "outputId": "099ac056-8a8b-4260-d4b5-334cd7e853c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average difference between data set is: -0.07834965\n"
          ]
        }
      ],
      "source": [
        "print(f'Average difference between data set is:', np.mean(age_difference))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c5d386",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
